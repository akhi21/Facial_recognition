{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training       28709\n",
      "PrivateTest     3589\n",
      "PublicTest      3589\n",
      "Name: Usage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Usage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val, 'float32'))\n",
    "            train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val, 'float32'))\n",
    "            test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index: {index} and row:{row}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample data : [array([ 70.,  80.,  82., ..., 106., 109.,  82.], dtype=float32), array([151., 150., 147., ..., 193., 183., 184.], dtype=float32)]\n",
      "train_y sample data : [0, 0]\n",
      "X_test sample data : [array([254., 254., 254., ...,  42., 129., 180.], dtype=float32), array([156., 184., 198., ..., 172., 167., 161.], dtype=float32)]\n",
      "test_y sample data : [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train sample data : {X_train[0:2]}\")\n",
    "print(f\"train_y sample data : {train_y[0:2]}\")\n",
    "print(f\"X_test sample data : {X_test[0:2]}\")\n",
    "print(f\"test_y sample data : {test_y[0:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train-=np.mean(X_train,axis=0)\n",
    "X_train/=np.std(X_train, axis=0)\n",
    "\n",
    "X_test-=np.mean(X_test,axis=0)\n",
    "X_test/=np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs=30\n",
    "width, height = 48,48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],width,height,1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0],width,height,1)\n",
    "\n",
    "train_y = np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y = np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', input_shape = (X_train.shape[1:])))\n",
    "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(num_features, (3,3),activation='relu'))\n",
    "model.add(Conv2D(num_features,(3,3) ,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, (3,3),activation='relu'))\n",
    "model.add(Conv2D(2*num_features,(3,3) ,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2*2*2*2*num_features,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2*2*2*2*num_features,activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_labels, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer = Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 1.7293 - accuracy: 0.2930 - val_loss: 1.7215 - val_accuracy: 0.3410\n",
      "Epoch 2/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 1.5150 - accuracy: 0.4007 - val_loss: 1.3906 - val_accuracy: 0.4631\n",
      "Epoch 3/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 1.4021 - accuracy: 0.4553 - val_loss: 1.3245 - val_accuracy: 0.4907\n",
      "Epoch 4/30\n",
      "28709/28709 [==============================] - 333s 12ms/step - loss: 1.3351 - accuracy: 0.4828 - val_loss: 1.2694 - val_accuracy: 0.5099\n",
      "Epoch 5/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 1.2903 - accuracy: 0.5030 - val_loss: 1.2589 - val_accuracy: 0.5149\n",
      "Epoch 6/30\n",
      "28709/28709 [==============================] - 351s 12ms/step - loss: 1.2515 - accuracy: 0.5192 - val_loss: 1.2221 - val_accuracy: 0.5397\n",
      "Epoch 7/30\n",
      "28709/28709 [==============================] - 333s 12ms/step - loss: 1.2273 - accuracy: 0.5295 - val_loss: 1.2178 - val_accuracy: 0.5261\n",
      "Epoch 8/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 1.1973 - accuracy: 0.5394 - val_loss: 1.1994 - val_accuracy: 0.5447\n",
      "Epoch 9/30\n",
      "28709/28709 [==============================] - 339s 12ms/step - loss: 1.1725 - accuracy: 0.5518 - val_loss: 1.1729 - val_accuracy: 0.5573\n",
      "Epoch 10/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 1.1586 - accuracy: 0.5534 - val_loss: 1.1741 - val_accuracy: 0.5453\n",
      "Epoch 11/30\n",
      "28709/28709 [==============================] - 337s 12ms/step - loss: 1.1353 - accuracy: 0.5670 - val_loss: 1.1725 - val_accuracy: 0.5578\n",
      "Epoch 12/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 1.1168 - accuracy: 0.5730 - val_loss: 1.1536 - val_accuracy: 0.5609\n",
      "Epoch 13/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 1.0930 - accuracy: 0.5815 - val_loss: 1.1519 - val_accuracy: 0.5651\n",
      "Epoch 14/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 1.0844 - accuracy: 0.5866 - val_loss: 1.1608 - val_accuracy: 0.5528\n",
      "Epoch 15/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 1.0630 - accuracy: 0.5898 - val_loss: 1.1906 - val_accuracy: 0.5511\n",
      "Epoch 16/30\n",
      "28709/28709 [==============================] - 333s 12ms/step - loss: 1.0533 - accuracy: 0.5966 - val_loss: 1.1441 - val_accuracy: 0.5720\n",
      "Epoch 17/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 1.0314 - accuracy: 0.6060 - val_loss: 1.1546 - val_accuracy: 0.5620\n",
      "Epoch 18/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 1.0180 - accuracy: 0.6136 - val_loss: 1.1353 - val_accuracy: 0.5776\n",
      "Epoch 19/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 1.0045 - accuracy: 0.6167 - val_loss: 1.1636 - val_accuracy: 0.5634\n",
      "Epoch 20/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 0.9868 - accuracy: 0.6226 - val_loss: 1.1528 - val_accuracy: 0.5807\n",
      "Epoch 21/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 0.9821 - accuracy: 0.6236 - val_loss: 1.1809 - val_accuracy: 0.5531\n",
      "Epoch 22/30\n",
      "28709/28709 [==============================] - 339s 12ms/step - loss: 0.9619 - accuracy: 0.6335 - val_loss: 1.1647 - val_accuracy: 0.5665\n",
      "Epoch 23/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 0.9484 - accuracy: 0.6392 - val_loss: 1.1548 - val_accuracy: 0.5717\n",
      "Epoch 24/30\n",
      "28709/28709 [==============================] - 336s 12ms/step - loss: 0.9379 - accuracy: 0.6445 - val_loss: 1.1524 - val_accuracy: 0.5770\n",
      "Epoch 25/30\n",
      "28709/28709 [==============================] - 333s 12ms/step - loss: 0.9285 - accuracy: 0.6466 - val_loss: 1.1704 - val_accuracy: 0.5681\n",
      "Epoch 26/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 0.9088 - accuracy: 0.6544 - val_loss: 1.1811 - val_accuracy: 0.5690\n",
      "Epoch 27/30\n",
      "28709/28709 [==============================] - 334s 12ms/step - loss: 0.8956 - accuracy: 0.6579 - val_loss: 1.1630 - val_accuracy: 0.5729\n",
      "Epoch 28/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 0.8766 - accuracy: 0.6677 - val_loss: 1.1700 - val_accuracy: 0.5734\n",
      "Epoch 29/30\n",
      "28709/28709 [==============================] - 335s 12ms/step - loss: 0.8750 - accuracy: 0.6667 - val_loss: 1.1805 - val_accuracy: 0.5717\n",
      "Epoch 30/30\n",
      "28709/28709 [==============================] - 340s 12ms/step - loss: 0.8677 - accuracy: 0.6713 - val_loss: 1.1754 - val_accuracy: 0.5678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x4823cec8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, train_y , batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, test_y), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_json=model.to_json()\n",
    "with open(\"fer.json\",\"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
